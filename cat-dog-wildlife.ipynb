{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43fcdb46",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Installation to use tensor flow\n",
    "#!pip install tensor flow\n",
    "#pip install Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e8b5ba",
   "metadata": {},
   "source": [
    "# CCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce17028e",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 31, 31, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1605760   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1625539 (6.20 MB)\n",
      "Trainable params: 1625539 (6.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "#Create a sequential model for stack layers\n",
    "model = Sequential()\n",
    "\n",
    "#Conv2d one of our convloution layer which takes 32 kernals\n",
    "#The size of the input images are 64x64 using RGB \n",
    "#The activation function ReLU (Rectified Linear Unit)\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#MaxPooling2D downsamples our input images to reduce dimensions.\n",
    "#Then is put into a pool size of 2x2 for max window size. \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten()) #Flattening the input to make a multidimensional input\n",
    "model.add(Dense(128, activation='relu')) #Creates Dense layer and the number of neurons 128\n",
    "model.add(Dense(3, activation='softmax'))  # 3 classes: cat, dog, \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2658ff43",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e977c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model to monitor the training of the accuracy\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e0940d3",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14630 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#Creation of the images\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#Parameters for the images like rescaling and shearing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "#path to training set \n",
    "training_set = train_datagen.flow_from_directory('afhq/train', target_size=(64, 64), batch_size=32, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9bcf54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "458/458 [==============================] - 51s 110ms/step - loss: 0.4301 - accuracy: 0.8256\n",
      "Epoch 2/11\n",
      "458/458 [==============================] - 48s 105ms/step - loss: 0.2063 - accuracy: 0.9249\n",
      "Epoch 3/11\n",
      "458/458 [==============================] - 49s 107ms/step - loss: 0.1631 - accuracy: 0.9393\n",
      "Epoch 4/11\n",
      "458/458 [==============================] - 50s 110ms/step - loss: 0.1429 - accuracy: 0.9479\n",
      "Epoch 5/11\n",
      "458/458 [==============================] - 50s 110ms/step - loss: 0.1208 - accuracy: 0.9557\n",
      "Epoch 6/11\n",
      "458/458 [==============================] - 49s 107ms/step - loss: 0.1133 - accuracy: 0.9592\n",
      "Epoch 7/11\n",
      "458/458 [==============================] - 49s 107ms/step - loss: 0.1011 - accuracy: 0.9634\n",
      "Epoch 8/11\n",
      "458/458 [==============================] - 50s 109ms/step - loss: 0.0939 - accuracy: 0.9658\n",
      "Epoch 9/11\n",
      "458/458 [==============================] - 50s 109ms/step - loss: 0.0832 - accuracy: 0.9712\n",
      "Epoch 10/11\n",
      "458/458 [==============================] - 49s 108ms/step - loss: 0.0794 - accuracy: 0.9713\n",
      "Epoch 11/11\n",
      "458/458 [==============================] - 50s 108ms/step - loss: 0.0754 - accuracy: 0.9716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1bce690cfa0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model, Reduced the epochs from 25 to 11 for quicker run time\n",
    "model.fit(training_set, epochs=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1e24c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For loading the our model in a keras file\n",
    "model.save('my_animal_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075d4037",
   "metadata": {},
   "source": [
    "# Testing\n",
    "## User Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40bcc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "#tkinter is the GUI\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import random\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = load_model('my_animal_model.keras')\n",
    "\n",
    "# The animal classes\n",
    "classes = ['Cat', 'Dog', 'Wildlife']\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_animal():\n",
    "    # Get user input\n",
    "    user_input = entry.get().lower()\n",
    "    #Valid input\n",
    "    animal_options = ['cat', 'dog', 'wild']\n",
    "    # Check if the user input is valid\n",
    "    if user_input not in animal_options:\n",
    "        result_label.config(text=\"Invalid input. Please enter 'cat', 'dog', or 'wild'\")\n",
    "        return\n",
    "\n",
    "    # Generate a random image number for the images from our dataset\n",
    "    animal_img_number = random.randint(1, 500)\n",
    "\n",
    "    # The image path to our test dataset \n",
    "    img_path = f'afhq/test/{user_input}/{user_input} ({animal_img_number}).jpg'\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(img_path, target_size=(64, 64))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = loaded_model.predict(img_array)\n",
    "\n",
    "    # Get the predicted class label\n",
    "    predicted_class = classes[np.argmax(predictions)]\n",
    "\n",
    "    # Display the image\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((300, 300), Image.LANCZOS)\n",
    "    img = ImageTk.PhotoImage(img)\n",
    "    image_label.config(image=img)\n",
    "    image_label.image = img\n",
    "\n",
    "    # The result label updated with user input\n",
    "    result_label.config(text=f'The Animal Prediction: {predicted_class}')\n",
    "\n",
    "# The main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Animal Prediction AI\")\n",
    "\n",
    "# UI components\n",
    "entry_label = tk.Label(window, text=\"Enter animal (cat, dog, wild):\")\n",
    "entry = tk.Entry(window)\n",
    "predict_button = tk.Button(window, text=\"ENTER\", command=predict_animal)\n",
    "result_label = tk.Label(window, text=\"\")\n",
    "image_label = tk.Label(window)\n",
    "\n",
    "# UI pack components\n",
    "#Applied padding for seperation\n",
    "entry_label.pack(padx=5, pady=5)\n",
    "entry.pack(padx=5, pady=5)\n",
    "predict_button.pack(padx=5, pady=5)\n",
    "result_label.pack(padx=5, pady=5)\n",
    "image_label.pack()\n",
    "\n",
    "# Run the GUI\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fee567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
